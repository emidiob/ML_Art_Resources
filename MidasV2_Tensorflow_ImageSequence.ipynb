{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emidiob/ML_Art_Resources/blob/main/MidasV2_Tensorflow_ImageSequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you find these notebooks helpful, support by following me on [Instagram](https://www.instagram.com/emidiobattipaglia/) and [Twitter](https://twitter.com/Emidio_B)**"
      ],
      "metadata": {
        "id": "vc6w3Hau2RY1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VW74rvzS_p9"
      },
      "source": [
        "# ⭕ Check Hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GbWHmLgS1ZD"
      },
      "outputs": [],
      "source": [
        "print('CPU:') \n",
        "!lscpu |grep 'Model name'\n",
        "print('GPU:') \n",
        "!nvidia-smi -q\n",
        "!nvidia-smi\n",
        "print('Memory:') \n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "print('Memory Info:') \n",
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDW_HymE99mr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApYlqYr-zRo8"
      },
      "source": [
        "# ⭕ Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0VymBzFzTj9",
        "outputId": "a1e1e3df-9468-4883-bf79-9a8b2753ba65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWBOZVH_T2lW"
      },
      "source": [
        "#⭕ Move the archive in the main directory and unzip files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pxEHIVKXT-M"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/midas/input.zip /content/\n",
        "\n",
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/input.zip\",outdir='/content/')\n",
        "\n",
        "!rm /content/input.zip\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgqH0KWSjs3b"
      },
      "source": [
        "#⭕ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoXOwSHvDo_t"
      },
      "outputs": [],
      "source": [
        "pip install timm tensorflow tensorflow-hub opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Dd2WmNuSik"
      },
      "source": [
        "# ⭕ Import libraries and create Export folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eVHZCLyDRBE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "\n",
        "path = \"/content/export\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % path)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY55OhA6ub6I"
      },
      "source": [
        "#⭕ Analize and export images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd5hAE32DVXd"
      },
      "outputs": [],
      "source": [
        "# the runtime initialization will not allocate all memory on the device to avoid out of GPU memory\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    #tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    tf.config.experimental.set_virtual_device_configuration(gpu,\n",
        "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
        "\n",
        "# load model\n",
        "module = hub.load(\"https://tfhub.dev/intel/midas/v2/2\", tags=['serve'])\n",
        "\n",
        "directory = r'/content/input'\n",
        "for entry in os.scandir(directory):\n",
        "    if (entry.path.endswith(\".jpg\")\n",
        "            or entry.path.endswith(\".png\")\n",
        "                    or entry.path.endswith(\".jpeg\")) and entry.is_file():\n",
        "        print(\"Analizzo l'immagine\", entry.name)\n",
        "        #filename = entry.path\n",
        "        # input\n",
        "        img = cv2.imread(entry.path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "        img_resized = tf.image.resize(img, [384,384], method='bicubic', preserve_aspect_ratio=False, align_corners=True)\n",
        "        img_resized = tf.transpose(img_resized, [2, 0, 1])\n",
        "        img_input = img_resized.numpy()\n",
        "        reshape_img = img_input.reshape(1,3,384,384)\n",
        "        tensor = tf.convert_to_tensor(reshape_img, dtype=tf.float32)\n",
        "\n",
        "\n",
        "        output = module.signatures['serving_default'](tensor)\n",
        "        prediction = output['default'].numpy()\n",
        "        prediction = prediction.reshape(384, 384)\n",
        "                    \n",
        "        # output file\n",
        "        prediction = cv2.resize(prediction, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "        print(\" Write image to:\", entry.name)\n",
        "        depth_min = prediction.min()\n",
        "        depth_max = prediction.max()\n",
        "        img_out = (255 * (prediction - depth_min) / (depth_max - depth_min)).astype(\"uint8\")\n",
        "\n",
        "        #cv2.imwrite(entry.name, img_out)\n",
        "\n",
        "        #path = '/content/export'\n",
        "        #cv2.imwrite(os.path.join(path , entry.name), img)\n",
        "        cv2.imwrite(f'/content/export/{entry.name}',img_out)\n",
        "        #plt.imshow(img_out)\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "!zip -r /content/export.zip /content/export\n",
        "\n",
        "!cp /content/export.zip /content/drive/MyDrive/midas/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3VW74rvzS_p9",
        "s0YP7qe-1siD",
        "PR3nE8xRjmpn",
        "3pZ2PLw_uj2j",
        "osFG6GRtuns7"
      ],
      "machine_shape": "hm",
      "name": "MidasV2_Tensorflow_ImageSequence.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}